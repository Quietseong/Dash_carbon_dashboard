"""
í–¥ìƒëœ íƒ„ì†Œ RAG ì—ì´ì „íŠ¸
ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬, ì¿¼ë¦¬ ë¶„ì„, ì‹œê°í™” ì—”ì§„ì„ í†µí•©í•œ AI ì—ì´ì „íŠ¸
"""

import os
import pandas as pd
import numpy as np
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ ì‹œë„ (ì•ˆì „í•œ ë°©ì‹)
env_loaded = False
try:
    # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
    load_dotenv(encoding='utf-8')
    env_loaded = True
except UnicodeDecodeError:
    try:
        # CP949 ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
        load_dotenv(encoding='cp949')
        env_loaded = True
    except Exception:
        try:
            # Latin1 ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
            load_dotenv(encoding='latin1')
            env_loaded = True
        except Exception:
            pass
except Exception:
    pass

if not env_loaded:
    print("âš ï¸ .env íŒŒì¼ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•´ì£¼ì„¸ìš”.")

from typing import List, Dict, Tuple, Optional, Any

# langchain_upstage ëª¨ë“ˆ import
try:
    from langchain_upstage import ChatUpstage
    LLM_PROVIDER = "upstage"
except ImportError:
    print("âš ï¸ langchain_upstage ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAIë¥¼ ëŒ€ì²´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    try:
        from langchain_openai import ChatOpenAI as ChatUpstage
        LLM_PROVIDER = "openai"
    except ImportError:
        raise ImportError("langchain_upstage ë˜ëŠ” langchain_openai ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤.")

from langchain.schema import HumanMessage, SystemMessage
import warnings

# ìƒˆë¡œ êµ¬í˜„í•œ ëª¨ë“ˆë“¤ import
from .data_preprocessor import DataPreprocessor
from .query_analyzer import QueryAnalyzer, QueryIntent
from .visualization_engine import VisualizationEngine
from .metadata_manager import MetadataManager
from .code_executor import SafeCodeExecutor

warnings.filterwarnings('ignore')

# í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ì„¤ì •
if not os.getenv('UPSTAGE_API_KEY'):
    print("ðŸ”§ í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•©ë‹ˆë‹¤...")
    os.environ['UPSTAGE_API_KEY'] = 'up_Tfh3KhtojqHp2MascmzOv3IG4lDu0'

class EnhancedCarbonRAGAgent:
    """í–¥ìƒëœ íƒ„ì†Œ ë°ì´í„° RAG ì—ì´ì „íŠ¸"""
    
    _instance = None
    
    def __new__(cls):
        """ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„"""
        if cls._instance is None:
            cls._instance = super(EnhancedCarbonRAGAgent, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        if hasattr(self, '_initialized'):
            return
            
        # LLM ì´ˆê¸°í™”
        try:
            if LLM_PROVIDER == "upstage":
                self.api_key = os.getenv('UPSTAGE_API_KEY')
                if not self.api_key:
                    raise ValueError("UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
                self.llm = ChatUpstage(
                    api_key=self.api_key,
                    model="solar-mini-250123"
                )
                print("âœ… Upstage LLM ì´ˆê¸°í™” ì™„ë£Œ")
            else:  # OpenAI
                self.api_key = os.getenv('OPENAI_API_KEY')
                if not self.api_key:
                    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
                self.llm = ChatUpstage(
                    api_key=self.api_key,
                    model="gpt-3.5-turbo"
                )
                print("âœ… OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            raise RuntimeError(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë°ì´í„° í´ë” ê²½ë¡œ
        self.data_folder = "data"
        
        # ê³ ê¸‰ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.data_preprocessor = DataPreprocessor(self.data_folder)
        self.query_analyzer = QueryAnalyzer()
        self.visualization_engine = VisualizationEngine()
        self.metadata_manager = MetadataManager("agent/metadata.json")
        self.code_executor = SafeCodeExecutor()
        
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self._load_and_process_data()
        
        self._initialized = True
        print("âœ… í–¥ìƒëœ íƒ„ì†Œ RAG ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _load_and_process_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ðŸ”„ ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì¤‘...")
        
        # 1. ëª¨ë“  ë°ì´í„°ì…‹ ë¶„ì„
        self.dataset_info = self.data_preprocessor.analyze_all_datasets()
        
        # 2. ë°ì´í„° í‘œì¤€í™” ë° í†µí•©
        self.unified_data = self.data_preprocessor.standardize_data()
        
        # 3. ë©”íƒ€ë°ì´í„° ìƒì„±
        self.metadata_manager.analyze_and_create_metadata(self.data_preprocessor.datasets)
        
        # 4. ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
        self.data_summary = self.data_preprocessor.get_data_summary()
        
        print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì´ {self.data_summary['total_datasets']}ê°œ ë°ì´í„°ì…‹ ë¡œë“œ")
        if self.unified_data is not None:
            print(f"   - í†µí•© ë°ì´í„°: {self.unified_data.shape[0]}í–‰ Ã— {self.unified_data.shape[1]}ì—´")
            print(f"   - ì—°ë„ ë²”ìœ„: {self.data_summary['year_range']}")
    
    def ask(self, question: str) -> Tuple[str, Optional[str]]:
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ë° ì‹œê°í™” ìƒì„±
        
        Args:
            question: ì‚¬ìš©ìž ì§ˆë¬¸
            
        Returns:
            (ë‹µë³€ í…ìŠ¤íŠ¸, ì‹œê°í™” ì´ë¯¸ì§€ base64)
        """
        try:
            print(f"ðŸŽ¯ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œìž‘: '{question}'")
            
            # 1. ì§ˆë¬¸ ì˜ë„ ë¶„ì„
            intent = self.query_analyzer.analyze_query(question)
            print(f"ðŸ” ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ: {intent.query_type.value} (ì‹ ë¢°ë„: {intent.confidence:.2f})")
            print(f"ðŸ“… ì¶”ì¶œëœ ì—°ë„: {intent.years}")
            print(f"ðŸ·ï¸ ì¶”ì¶œëœ ì—”í‹°í‹°: {intent.entities}")
            
            # 2. ì‹œê°í™” í•„ìš”ì„± íŒë‹¨
            needs_viz = self.query_analyzer.needs_visualization(question)
            print(f"ðŸ“Š ì‹œê°í™” í•„ìš”: {needs_viz}")
            
            # 3. ë°ì´í„° í•„í„°ë§ ë° ë¶„ì„
            analysis_result = self._perform_data_analysis(intent)
            print(f"ðŸ“ˆ ë¶„ì„ ê²°ê³¼ ì„±ê³µ: {analysis_result.get('success', False)}")
            if 'data' in analysis_result:
                print(f"ðŸ“Š ë¶„ì„ëœ ë°ì´í„° í¬ê¸°: {len(analysis_result['data']) if analysis_result['data'] is not None else 0}")
            
            # 4. ì‹œê°í™” ìƒì„± (í•„ìš”í•œ ê²½ìš°ë§Œ)
            visualization = None
            if needs_viz:
                print("ðŸŽ¨ ì‹œê°í™” ìƒì„± ì‹œìž‘...")
                visualization = self._create_visualization(intent, analysis_result)
                if visualization:
                    print("âœ… ì‹œê°í™” ìƒì„± ì™„ë£Œ")
                else:
                    print("âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨")
            else:
                print("â„¹ï¸ í…ìŠ¤íŠ¸ ë‹µë³€ë§Œ ì œê³µ")
            
            # 5. ë‹µë³€ ìƒì„±
            answer = self._generate_answer(question, intent, analysis_result)
            
            return answer, visualization
            
        except Exception as e:
            error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return error_msg, None
    
    def _perform_data_analysis(self, intent: QueryIntent) -> Dict[str, Any]:
        """ì§ˆë¬¸ ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
        if self.unified_data is None or self.unified_data.empty:
            return {"error": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # ì½”ë“œ ìƒì„± ë° ì‹¤í–‰
            context = {"unified_data": self.unified_data}
            
            # ì§ˆë¬¸ ì˜ë„ì— ë”°ë¥¸ ë¶„ì„ ì½”ë“œ ìƒì„±
            analysis_code = self.code_executor.generate_analysis_code(
                intent, 
                list(self.unified_data.columns)
            )
            
            # ì½”ë“œ ì‹¤í–‰
            success, result, output = self.code_executor.execute_code(analysis_code, context)
            
            if success and result is not None:
                return {
                    "success": True,
                    "data": result,
                    "output": output,
                    "code": analysis_code
                }
            else:
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
                return self._fallback_analysis(intent)
                
        except Exception as e:
            print(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._fallback_analysis(intent)
    
    def _fallback_analysis(self, intent: QueryIntent) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ì„ (ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ)"""
        try:
            # êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©
            inventory_dataset = None
            for dataset_name, df in self.data_preprocessor.datasets.items():
                if 'êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬' in dataset_name:
                    inventory_dataset = df
                    print(f"ðŸ“Š êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ì…‹ ì‚¬ìš©: {dataset_name}")
                    break
            
            if inventory_dataset is None or inventory_dataset.empty:
                return {"error": "êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # ì—°ë„ í•„í„°ë§
            if intent.years:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ì—°ë„ (ì´ë¯¸ data_preprocessorì—ì„œ í™•ì¸ë¨)
                year_mask = inventory_dataset.iloc[:, 0].isin(intent.years)
                filtered_data = inventory_dataset[year_mask].copy()
                print(f"ðŸ“… ì—°ë„ í•„í„°ë§: {intent.years} â†’ {len(filtered_data)}ê°œ ë ˆì½”ë“œ")
            else:
                filtered_data = inventory_dataset.copy()
            
            # ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
            result_data = []
            
            # ì§ˆë¬¸ íƒ€ìž…ë³„ ë¶„ì„
            if intent.query_type.value == 'comparison' and intent.years:
                # ì—°ë„ë³„ ë¹„êµ: ê° ì—°ë„ì˜ ì´ë°°ì¶œëŸ‰ (ë‘ ë²ˆì§¸ ì»¬ëŸ¼)
                for year in intent.years:
                    year_row = inventory_dataset[inventory_dataset.iloc[:, 0] == year]
                    if not year_row.empty:
                        total_emission = year_row.iloc[0, 1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ ì´ë°°ì¶œëŸ‰
                        result_data.append({
                            'year': year,
                            'value': total_emission
                        })
                        print(f"ðŸ“ˆ {year}ë…„ ì´ë°°ì¶œëŸ‰: {total_emission:,.1f} (ë°±ë§Œí†¤ COâ‚‚)")
                
                result = pd.DataFrame(result_data)
                        
            elif intent.query_type.value == 'trend':
                # ì¶”ì„¸ ë¶„ì„: ëª¨ë“  ì—°ë„ì˜ ì´ë°°ì¶œëŸ‰
                for _, row in inventory_dataset.iterrows():
                    year = row.iloc[0]
                    total_emission = row.iloc[1]
                    if pd.notna(year) and pd.notna(total_emission):
                        result_data.append({
                            'year': int(year),
                            'value': float(total_emission)
                        })
                
                result = pd.DataFrame(result_data).sort_values('year')
            else:
                # ê¸°ë³¸: ìš”ì²­ëœ ì—°ë„ë“¤ì˜ ë°ì´í„°
                for _, row in filtered_data.iterrows():
                    year = row.iloc[0]
                    total_emission = row.iloc[1]
                    if pd.notna(year) and pd.notna(total_emission):
                        result_data.append({
                            'year': int(year),
                            'value': float(total_emission)
                        })
                
                result = pd.DataFrame(result_data)
            
            if result.empty:
                return {"error": "ìš”ì²­í•œ ì—°ë„ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            return {
                "success": True,
                "data": result,
                "output": f"êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë¶„ì„ ì™„ë£Œ - ì´ë°°ì¶œëŸ‰ ê¸°ì¤€ (ë°±ë§Œí†¤ COâ‚‚)"
            }
            
        except Exception as e:
            print(f"ê¸°ë³¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {"error": f"ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _create_visualization(self, intent: QueryIntent, analysis_result: Dict[str, Any]) -> Optional[str]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œê°í™” ìƒì„±"""
        if not analysis_result.get("success") or analysis_result.get("data") is None:
            return None
        
        try:
            data = analysis_result["data"]
            
            # ì‹œê°í™” ë§¤ê°œë³€ìˆ˜ ìƒì„±
            viz_params = self.query_analyzer.suggest_visualization_params(intent)
            
            # ì°¨íŠ¸ ì œëª© ìƒì„±
            title = self._generate_chart_title(intent)
            
            # ì‹œê°í™” ìƒì„±
            visualization = self.visualization_engine.create_visualization(
                data=data,
                chart_type=intent.chart_type.value,
                title=title,
                params=viz_params
            )
            
            return visualization
            
        except Exception as e:
            print(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def _generate_chart_title(self, intent: QueryIntent) -> str:
        """ì°¨íŠ¸ ì œëª© ìƒì„±"""
        if intent.query_type.value == 'comparison' and intent.years:
            if len(intent.years) == 2:
                return f"{intent.years[0]}ë…„ê³¼ {intent.years[1]}ë…„ ë°°ì¶œëŸ‰ ë¹„êµ"
            else:
                return f"{min(intent.years)}-{max(intent.years)}ë…„ ë°°ì¶œëŸ‰ ë¹„êµ"
        elif intent.query_type.value == 'trend':
            return "ì—°ë„ë³„ ë°°ì¶œëŸ‰ ë³€í™” ì¶”ì´"
        elif intent.query_type.value == 'ranking':
            return "ë¶„ì•¼ë³„ ë°°ì¶œëŸ‰ ìˆœìœ„"
        else:
            return "ë°°ì¶œëŸ‰ ë¶„ì„ ê²°ê³¼"
    
    def _generate_answer(self, question: str, intent: QueryIntent, analysis_result: Dict[str, Any]) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        try:
            # ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(analysis_result)
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±
            system_message = f"""
ë‹¹ì‹ ì€ íƒ„ì†Œ ë°°ì¶œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë°ì´í„° ë¶„ì„ ê²°ê³¼:
{context}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
1. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ë‹µë³€í•˜ì„¸ìš”
2. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
3. ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
4. ê°€ëŠ¥í•œ ê²½ìš° íŠ¸ë Œë“œë‚˜ íŒ¨í„´ì„ ì–¸ê¸‰í•˜ì„¸ìš”
5. 200ìž ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
"""
            
            # ì‚¬ìš©ìž ì§ˆë¬¸
            user_message = f"ì§ˆë¬¸: {question}"
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_message),
                HumanMessage(content=user_message)
            ]
            
            response = self.llm.invoke(messages)
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(response, 'content'):
                answer = response.content
            else:
                answer = str(response)
            
            return answer.strip()
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise RuntimeError(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _build_context(self, analysis_result: Dict[str, Any]) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        if not analysis_result.get('success', False):
            return "ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        
        # ë°ì´í„° ì •ë³´
        if 'data' in analysis_result and analysis_result['data'] is not None:
            data = analysis_result['data']
            if hasattr(data, 'shape'):
                context_parts.append(f"ë¶„ì„ëœ ë°ì´í„°: {data.shape[0]}ê°œ í–‰")
            
            # ìˆ˜ì¹˜ ë°ì´í„° ìš”ì•½
            if hasattr(data, 'describe'):
                try:
                    stats = data.describe()
                    context_parts.append(f"í†µê³„ ìš”ì•½: {stats.to_string()}")
                except:
                    pass
        
        # ì¶œë ¥ ê²°ê³¼
        if 'output' in analysis_result:
            context_parts.append(f"ë¶„ì„ ì¶œë ¥: {analysis_result['output']}")
        
        return "\n".join(context_parts) if context_parts else "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

    def get_available_data_info(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        info_parts = ["ðŸ“Š **ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:**\n"]
        
        for name, info in self.dataset_info.items():
            info_parts.append(f"**{name}**")
            info_parts.append(f"- {info.description}")
            info_parts.append(f"- í¬ê¸°: {info.shape[0]}í–‰ Ã— {info.shape[1]}ì—´")
            if info.has_year_columns:
                years = [str(col) for col in info.year_columns[:5]]  # ì²˜ìŒ 5ê°œë§Œ
                info_parts.append(f"- ì—°ë„: {', '.join(years)}...")
            info_parts.append("")
        
        # í†µí•© ë°ì´í„° ì •ë³´
        if self.unified_data is not None:
            info_parts.append("**ðŸ“ˆ í†µí•© ë¶„ì„ ë°ì´í„°:**")
            info_parts.append(f"- ì „ì²´ ë ˆì½”ë“œ: {len(self.unified_data):,}ê°œ")
            info_parts.append(f"- ì—°ë„ ë²”ìœ„: {self.data_summary['year_range']}")
            info_parts.append(f"- ë°ì´í„°ì…‹ ìˆ˜: {self.data_summary['datasets_in_unified']}ê°œ")
        
        return "\n".join(info_parts)
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "datasets_loaded": len(self.dataset_info),
            "unified_data_size": len(self.unified_data) if self.unified_data is not None else 0,
            "metadata_available": len(self.metadata_manager.metadata),
            "execution_history": self.code_executor.get_execution_summary(),
            "data_summary": self.data_summary
        }
    
    def debug_query(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë””ë²„ê¹… ì •ë³´ ì œê³µ"""
        intent = self.query_analyzer.analyze_query(question)
        
        return {
            "question": question,
            "intent": {
                "query_type": intent.query_type.value,
                "chart_type": intent.chart_type.value,
                "years": intent.years,
                "entities": intent.entities,
                "metrics": intent.metrics,
                "confidence": intent.confidence
            },
            "suggested_params": self.query_analyzer.suggest_visualization_params(intent),
            "available_data": list(self.dataset_info.keys())
        } 